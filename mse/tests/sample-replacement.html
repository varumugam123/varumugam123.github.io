<!--
    Usage:
    logEvents=true // log video element events
    moderateTimeupdateLogging=true // moderate timeupdate events

    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideo=true // video will be reenqueued (implicit) at default time 2.5 seconds
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=5
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=5&removeDataOnReenqueue=true // video will be reenqueued at 5 seconds and data will be removed before reenqueueing (explicit)

    sample-replacement.html?moderateTimeupdateLogging=true&audio=true&reenqueueVideo=true&reenqueueVideoAt=5 // audio will be playing, but only video samples will be reenqueued (implicit)
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=5&reenqueueAudioAt=3 // video will be reenqueued at 5 seconds and audio will be reenqueued at 3 seconds (implicity)
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=5&reenqueueAudioAt=3&removeDataOnReenqueue=true // video & audio will be reenqueued and data will be removed before reenqueueing (explicit)
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=3&reenqueueAudioAt=5&removeDataOnReenqueue=true // video & audio will be reenqueued and data will be removed before reenqueueing (explicit)

    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=3&reenqueueAudioAt=3 // video & audio will be reenqueued (implicit)
    sample-replacement.html?moderateTimeupdateLogging=true&reenqueueVideoAt=3&reenqueueAudioAt=3&removeDataOnReenqueue=true // video & audio will be reenqueued and data will be removed before reenqueueing (explicit)
 -->

<!DOCTYPE html>
<html>
    <head>
        <meta charset='UTF-8' />
        <meta http-equiv='Cache-Control' content='no-cache, no-store, must-revalidate' />
        <meta http-equiv='Pragma' content='no-cache' />
        <meta http-equiv='Expires' content='0' />
        <title>MSE Test</title>

        <style>
        video {
            width: 100%;
            height: 100%;
        }
        body {
            margin:0;
            padding:0;
            background-color:transparent;
            overflow: hidden;
        }
        #stats {
            position: absolute;
            left: 10px;
            top: 10px;
            background-color: grey;
            color: white;
            font-size: xx-large;
        }
        #errors {
            position: absolute;
            /* left: 10px; */
            top: 250px;
            background-color: red;
            font-size: xx-large;
        }
        </style>
    </head>

    <body>
        <div>
            <video id='videoPlayer' controls autoplay muted=false></video>
            <div>
                <span id='stats'/>
            </div>
            <div style="text-align:center;" >
                <span id='errors'></span>
            </div>
        </div>

        <script src="../lib/utils.js"></script>
        <script src="../lib/mse.js"></script>

        <script src="../lib/logging.js"></script>
        <script src="../lib/common.js"></script>
        <script src="../lib/big_buck_bunny_720p_30fps.js"></script>
        <script src="../lib/red_bull.js"></script>
        <script src="../lib/feeder.js"></script>

        <script type='text/javascript'>
            if (!window.MediaSource) {
                throw 'No Media Source API available'
            }

            var reenqueueVideoAt = getParamValue('reenqueueVideoAt')
            var reenqueueAudioAt = getParamValue('reenqueueAudioAt')
            var reenqueueVideo = checkProp('reenqueueVideo') || (reenqueueVideoAt != -1)
            var reenqueueAudio = checkProp('reenqueueAudio') || (reenqueueAudioAt != -1)
            var removeDataOnReenqueue = checkProp('removeDataOnReenqueue')
            var enableAudio = checkProp('audio') || reenqueueAudio

            if(reenqueueVideoAt != -1 && reenqueueAudioAt == -1)
                reenqueueAudioAt = reenqueueVideoAt;
            else if(reenqueueAudioAt != -1 && reenqueueVideoAt == -1)
                reenqueueVideoAt = reenqueueAudioAt;
            else if(reenqueueAudioAt == -1 && reenqueueVideoAt == -1) {
                reenqueueVideoAt = 2.5;
                reenqueueAudioAt = 2.5;
            }

            var sentTestStatus = false;
            var testPassed = false;
            const testContent = new RedBullContent();

            function cleanup() {
                performCommonCleanup();

                if (!sentTestStatus) {
                    sentTestStatus = true;
                    if (testPassed) {
                        document.querySelector('#errors').style.backgroundColor = 'Green';
                        document.querySelector('#errors').innerHTML = "Test Passed";
                        reportPass(true, "Test Passed")
                    } else {
                        document.querySelector('#errors').innerHTML = "Test Failed";
                        reportFail(false, "Test Failed")
                    }
                }
            }

            function onFeedEnded() {
                for (let key in feeders)
                    if (feeders.hasOwnProperty(key) && feeders[key] && !(feeders[key].ended))
                        return
                logMsg("All feeders ended");

                if(window.scheduledMonitorForEnded === undefined) {
                    window.scheduledMonitorForEnded = true;

                    waitForCondition(function () {
                            return (video.currentTime >= (video.duration - 1));
                        }, ((video.duration - video.currentTime) * 1000) + 1000)
                    .then(() => {
                        testPassed = true;
                        logMsg("Test completed successfully");
                        cleanup();
                    }).catch((error) => {
                        logMsg("Test Failed, " + error);
                        cleanup()
                    })
                }
            }

            function checkBufferPercentageAndwaitForCondition(isVideo, bufferPercentage) {
                // logMsg("checkBufferPercentageAndwaitForCondition: " + isVideo + " : " + video.readyState.toString() + ", " + bufferPercentage);

                let feeder = isVideo ? feeders.video : feeders.audio;
                if(feeder === undefined || feeder == null)
                    return;

                // wait for two buffers (including initialization segment) to start playback from 0 and wait for 1 buffer on reenqueue
                let buffersToStartMonitoringForPlaying = (feeder.reenqueue && feeder.doneReenqueuing) ? 1 : 2;

                // Once enough buffers to get the playback started are appended remove appendBufferCompletion monitoring
                if(feeder.bufferCount == buffersToStartMonitoringForPlaying)
                    feeder.appendComplete = undefined;

                let allSourceBuffersHaveData = allFeedersMeetCondition((feeder, isVideo) => {
                    return (feeder.appendComplete === undefined);
                });

                // When all sources have enough buffers to get started
                if (allSourceBuffersHaveData) {
                    waitForCondition(checkForPlaying, 10000, "Enough data is fed, but playback hasn't started").then(() => {
                        logMsg("Player started playback");
                        if(feeder.doneReenqueuing) {
                            // Determine the expected time from video.currentTime
                            let expectedTime = isVideo ? feeders.video.timeOfReenqueue : feeders.audio.timeOfReenqueue
                            let gracePeriod = expectedTime + 0.5 // tolerate flucutations until this point in time

                            let min = video.duration;
                            let max = 0;
                            forAllFeeders((feeder, isVideo) => {
                                if(feeder.timeOfReenqueue > 0) {
                                    if(feeder.timeOfReenqueue > max)
                                        max = feeder.timeOfReenqueue

                                    if(feeder.timeOfReenqueue < min)
                                        min = feeder.timeOfReenqueue
                                }
                            });

                            // If both buffers reenqueue close to each other
                            // until the last buffer's reenqueue + 0.5 time
                            // tolerate any fluctuations (but video.currentTime should be greater
                            // than the least of the reenqueue time)
                            if((max - min) <= 1) {
                                expectedTime = min
                                gracePeriod = max + 0.5
                            }

                            // Stop monitoring once we played beyond grace period and the next second
                            let finishMonitoringAt = gracePeriod + 1;

                            return monitorTimePolling(expectedTime, 100, 100, (time) => (time <= gracePeriod ? 0 : 0.090), () => (video.currentTime >= finishMonitoringAt));
                            // return monitorTimeOnUpdateEvent(video, expectedTime, 100, (time) => (time <= gracePeriod ? 0 : 0.200), () => (video.currentTime >= finishMonitoringAt));
                        }
                    }).catch((error) => {
                        logMsg(error);
                        cleanup()
                    })
                }
            }

            var finishOrRenenqueue = (isVideo) => {
                if (feeders.video == null && feeders.audio == null)
                    return;

                let feeder = (isVideo ? feeders.video : feeders.audio);
                let shouldReenqueue = (isVideo ? feeders.video.reenqueue : feeders.audio.reenqueue);
                let shouldRemoveFragment = (isVideo ? feeders.video.removeFragment : feeders.audio.removeFragment);
                let sourceBuffer = isVideo ? feeders.video.sourceBuffer : feeders.audio.sourceBuffer;

                if (shouldReenqueue) {
                    if (feeder.scheduledReenqueueAt !== undefined && feeder.scheduledReenqueueAt != -1 && video.currentTime < feeder.scheduledReenqueueAt) {
                        let delta = (feeder.scheduledReenqueueAt >= video.currentTime) ? (feeder.scheduledReenqueueAt - video.currentTime) * 1000 : 0;
                        let timeOut = (delta > 50) ? delta : 50;
                        logMsg("Scheduling task to reenqueue in " + timeOut + " ms, for " + (isVideo ? "Video" : "Audio") + " @ " + video.currentTime);
                        setTimeout(() => { finishOrRenenqueue(isVideo); }, timeOut);
                        return;
                    }

                    let timeOfReenqueue = video.currentTime;
                    let urls = testContent.getUrlsForTime(isVideo, timeOfReenqueue, 11.5, false)
                    var attachNewFeeder = function () {
                        let newFeeder = new Feeder(sourceBuffer, urls, onFeedEnded, checkBufferPercentageAndwaitForCondition, isVideo);
                        newFeeder.reenqueue = feeder.reenqueue;
                        newFeeder.scheduledReenqueueAt = feeder.scheduledReenqueueAt;
                        newFeeder.removeFragment = feeder.removeFragment;
                        newFeeder.timeOfReenqueue = timeOfReenqueue
                        newFeeder.doneReenqueuing= true;

                        if (isVideo)
                            feeders.video = newFeeder;
                        else
                            feeders.audio = newFeeder;

                        logMsg("Attached new feeder for " + (isVideo ? "Video" : "Audio"));
                    }

                    if (shouldRemoveFragment) {
                        sourceBuffer.onupdateend = () => {
                            sourceBuffer.onupdateend = undefined;
                            attachNewFeeder();
                        };
                        logMsg("Removing " + (isVideo ? "Video" : "Audio") + " buffers @ " + video.currentTime);
                        sourceBuffer.remove(0, 100);
                        logMsg("Removed " + (isVideo ? "Video" : "Audio") + " buffers {0,20}");
                    } else {
                        attachNewFeeder();
                    }
                } else {
                    onFeedEnded();
                }
            }

            function onSourceOpen() {
                ms.duration = 12 // maxFetchIdx * segmentDuration

                if (enableAudio) {
                    var audioBuffer = ms.addSourceBuffer(testContent.audioCodec)
                    feeders.audio = new Feeder(audioBuffer, testContent.getAudioUrlsForTime(0, 11.5, true), () => {
                        finishOrRenenqueue(false)
                    }, checkBufferPercentageAndwaitForCondition, false);
                }

                var videoBuffer = ms.addSourceBuffer(testContent.videoCodec)
                feeders.video = new Feeder(videoBuffer, testContent.getVideoUrlsForTime(0, 11.5, true), () => {
                    finishOrRenenqueue(true)
                }, checkBufferPercentageAndwaitForCondition, true);

                [true, false].forEach((isVideo) => {
                    let feeder = isVideo ? feeders.video : feeders.audio;
                    if(feeder === undefined || feeder == null)
                        return;
                    feeder.reenqueue = isVideo ? reenqueueVideo : reenqueueAudio;
                    feeder.scheduledReenqueueAt = isVideo ? reenqueueVideoAt : reenqueueAudioAt;
                    feeder.removeFragment = removeDataOnReenqueue;
                    feeder.doneReenqueuing = false
                    feeder.timeOfReenqueue = 0

                    logMsg((isVideo ? "Video" : "Audio") + ", Reenqueue:" + feeder.reenqueue + ", ReenqueueAt:" + feeder.scheduledReenqueueAt + ", RemoveDataOnReenqueue:" + feeder.removeFragment);
                })
            }

            let urlsToCache = testContent.getVideoUrlsForTime(0, 20, true);
            if (enableAudio)
                urlsToCache = urlsToCache.concat(testContent.getAudioUrlsForTime(0, 20, true));

            cacheMediaIfRequired(urlsToCache).then(() => {
                // calls onSourceOpen() when MSE is ready
                initializeMSE();
            }).catch((error) => {
                logMsg(error);
                cleanup();
            });
        </script>
    </body>
</html>