<!--
    Usage:
    logEvents=true // log video element events
    moderateTimeupdateLogging=true // moderate timeupdate events

    audio-switch.html?moderateTimeupdateLogging=true
-->

<!DOCTYPE html>
<html>
    <head>
        <meta charset='UTF-8' />
        <meta http-equiv='Cache-Control' content='no-cache, no-store, must-revalidate' />
        <meta http-equiv='Pragma' content='no-cache' />
        <meta http-equiv='Expires' content='0' />
        <title>MSE Test</title>

        <style>
        video {
            width: 100%;
            height: 100%;
        }
        body {
            margin:0;
            padding:0;
            background-color:transparent;
            overflow: hidden;
        }
        #stats {
            position: absolute;
            left: 10px;
            top: 10px;
            background-color: grey;
            color: white;
            font-size: xx-large;
        }
        #errors {
            position: absolute;
            /* left: 10px; */
            top: 250px;
            background-color: red;
            font-size: xx-large;
        }
        </style>
    </head>

    <body>
        <div>
            <video id='videoPlayer' controls autoplay muted=false></video>
            <div>
                <span id='stats'/>
            </div>
            <div style="text-align:center;" >
                <span id='errors'></span>
            </div>
        </div>

        <script src="../lib/utils.js"></script>
        <script src="../lib/mse.js"></script>

        <script src="../lib/logging.js"></script>
        <script src="../lib/common.js"></script>
        <script src="../lib/big_buck_bunny_720p_30fps.js"></script>
        <script src="../lib/red_bull.js"></script>
        <script src="../lib/feeder.js"></script>

        <script type='text/javascript'>
            if (!window.MediaSource) {
                throw 'No Media Source API available'
            }

            var enableAudio = true
            var triggerSimulation = true;
            var positionBeforeBufferRemoval = video.currentTime;

            var sentTestStatus = false;
            var testPassed = false;

            var testContent = new BBBContent();

            function cleanup() {
                performCommonCleanup();

                if (!sentTestStatus) {
                    sentTestStatus = true;
                    if (testPassed) {
                        document.querySelector('#errors').style.backgroundColor = 'Green';
                        document.querySelector('#errors').innerHTML = "Test Passed";
                        reportPass(true, "Test Passed")
                    } else {
                        document.querySelector('#errors').innerHTML = "Test Failed";
                        reportFail(false, "Test Failed")
                    }
                }
            }

            function onFeedEnded() {
                for (let key in feeders)
                    if (feeders.hasOwnProperty(key) && feeders[key] && !(feeders[key].ended))
                        return

                if(triggerSimulation) {
                    logMsg("All feeders ended, simulation is about to be triggered");

                    waitForCondition(() => { return (video.currentTime >= 3);}, (5 - video.currentTime) * 1000).then(() => {
                        simulateAudioLaunguageSwitch();
                    }).catch(() => {
                        logMsg("Video is not reached to 3 to trigger simulation");
                        cleanup()
                    })
                } else {
                    logMsg("All feeders ended after simulation");

                    waitForCondition(checkForPlaying, 5000, "All feeders ended, but playing event not received").then(() => {
                        return waitForCondition(function () {
                                    return (video.currentTime >= (video.duration - 1));
                                }, ((video.duration - video.currentTime) * 1000) + 1000, "Video is not reached to end of the video")
                    }).then(() => {
                        testPassed = true;
                        logMsg("Test completed successfully");
                        cleanup();
                    }).catch((error) => {
                        logMsg("Test Failed, " + error);
                        cleanup()
                    })
                }
            }

            function checkBufferPercentageAndwaitForCondition(isVideo, bufferPercentage) {
                // logMsg("checkBufferPercentageAndwaitForCondition: " + isVideo + " : " + video.readyState.toString() + ", " + bufferPercentage);

                if (video.readyState >= 1) {
                    if(isVideo) {
                        if (feeders.video)
                            feeders.video.appendComplete = undefined;
                    } else {
                        if (feeders.audio)
                            feeders.audio.appendComplete = undefined;
                    }

                    let allSourceBuffersHaveData = allFeedersMeetCondition((feeder, isVideo) => {
                        return (feeder.appendComplete === undefined);
                    });

                    if(allSourceBuffersHaveData) {
                        waitForEvent(video, 'canplay', 5000).then(() => {
                            logMsg("Data loaded");
                            return waitForEvent(video, 'playing', 10000)
                        }).then(() => {
                            logMsg("Player started playback");
                        }).catch((error) => {
                            logMsg(error + ", currentTime=" + video.currentTime);
                            cleanup()
                        })
                    }
                }
            }

            function showBanner(text) {
                if(this.showErrorBanner === undefined)
                    this.showErrorBanner = true;

                if(this.showErrorBanner) {
                    this.showErrorBanner = false;
                    logMsg(text);
                    document.getElementById('errors').innerHTML = text;
                }
            }

            var currentTimeValidatorId = -1
            var currentTimeValidator = function (annotation) {
                let currentTime = video.currentTime;
                clearTimer(currentTimeValidatorId);
                logMsg("video.currentTime=" + currentTime + annotation);
                if ((currentTime < positionBeforeBufferRemoval) && (positionBeforeBufferRemoval - currentTime) > 0.066) {
                    let errorMsg = `video.currentTime(${currentTime}) is less than the position when audio data was replaced (${positionBeforeBufferRemoval})`;
                    showBanner(errorMsg);
                    cleanup();
                    throw (errorMsg);
                }

                currentTimeValidatorId = scheduleTask(() => { currentTimeValidator(" @ 50 millisecond") }, 50);
            }

            function simulateAudioLaunguageSwitch() {
                if(!triggerSimulation)
                    return
                triggerSimulation = false;

                waitForTime(0).then(() => {
                    logMsg("Seeking to 13");
                    video.currentTime = 13;
                    return waitForEvent(video, 'seeked', 1000, "Seeked to 13, but seeked event not received")
                }).then(() => {
                    if (video.currentTime < 13)
                        throw "Seeked to 13, but currentTime is less than 13";

                    logMsg("Playing video after seeking to 13");
                    logMsg('Scheduling audio data replacement after 3 second');
                    return waitForTime(3000);
                }).then(() =>{
                    video.pause();
                    currentTimeValidator(" @ After pausing");

                    let audioFeeder = feeders.audio
                    if (!audioFeeder)
                        throw "Audio feeder is not available";

                    let audioSourceBuffer = audioFeeder.sourceBuffer
                    let promise = waitForEvent(audioSourceBuffer, 'updateend', 1000, "updateend for Audio buffer removal not received");
                    positionBeforeBufferRemoval = video.currentTime;
                    audioSourceBuffer.remove(0, 1000);
                    logMsg('Audio data removed')
                    return promise;
                }).then(() => {
                    currentTimeValidator(" @ Audio buffer removal completion");

                    let audioFeeder = feeders.audio
                    if (!audioFeeder)
                        throw "Audio feeder is not available";

                    positionBeforeBufferRemoval -= 0.010; // adjust timing slightly before to trigger seeked event
                    let audioSourceBuffer = audioFeeder.sourceBuffer
                    let promise = waitForEvent(audioSourceBuffer, 'updateend', 2000, "updateend for Audio buffer replacement not received")
                    feeders.audio = new Feeder(audioSourceBuffer, testContent.getAudioUrlsForTime(positionBeforeBufferRemoval, 20, false), onFeedEnded, checkBufferPercentageAndwaitForCondition, false);
                    return promise;
                }).then(() => {
                    currentTimeValidator(" @ Audio buffer replaced");
                    let promise = waitForEvent(video, 'seeked', 5000, "Seeked to " + positionBeforeBufferRemoval + ", but seeked event not received");
                    video.currentTime = positionBeforeBufferRemoval;
                    return promise;
                }).then(() => {
                    currentTimeValidator(" @ Seek to " + positionBeforeBufferRemoval + " completion");
                    video.play();
                    clearTimeout(currentTimeValidatorId)
                    currentTimeValidatorId = -1
                }).catch((error) => {
                    logMsg("Failure in simulation, " + error);
                    cleanup()
                })
            }

            function onSourceOpen() {
                ms.duration = 20 // maxFetchIdx * segmentDuration

                if (enableAudio) {
                    var audioBuffer = ms.addSourceBuffer(testContent.audioCodec)
                    feeders.audio = new Feeder(audioBuffer, testContent.getAudioUrlsForTime(0, 20, true), onFeedEnded, checkBufferPercentageAndwaitForCondition, false);
                }

                var videoBuffer = ms.addSourceBuffer(testContent.videoCodec)
                feeders.video = new Feeder(videoBuffer, testContent.getVideoUrlsForTime(0, 20, true), onFeedEnded, checkBufferPercentageAndwaitForCondition, true);
            }

            let urlsToCache = testContent.getVideoUrlsForTime(0, 20, true);
            if(enableAudio)
                urlsToCache = urlsToCache.concat(testContent.getAudioUrlsForTime(0, 20, true));

            cacheMediaIfRequired(urlsToCache).then(() => {
                // calls onSourceOpen() when MSE is ready
                initializeMSE();
            }).catch((error) => {
                logMsg(error);
                cleanup();
            });

        </script>
    </body>
</html>